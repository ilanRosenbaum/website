# https://www.robotstxt.org/robotstxt.html
User-agent: *
Disallow:

# Explicitly disallow known scraping tools
User-agent: scrapy
Disallow: /

User-agent: wget
Disallow: /

User-agent: curl
Disallow: /

# Crawl-delay directive (in seconds)
Crawl-delay: 10